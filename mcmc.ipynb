{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Markov Chain Monte Carlo"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\nnp.random.seed(123)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The Bayesics \n\nA Monte Carlo routine is a random numerical walk through a parameter space that calculates possible solutions to or integrations of a given function, and each realisation of the routine provides a different outcome. By combining all of these solutions, an approximation of the most likely answer is yielded with error bars, and the correct answer is likely to be contained within those error bars. A Monte Carlo chain is considered to be Markov if its next \"step\" in parameter space is only dependent on its current position, and not the history of the entire chain.\n\nThese types of algorithms are usually implemented when scientists are faced with complex models for which other computational approaches are not appropriate. For example, Markov Chain Monte Carlo (MCMC) may be chosen when a least squares fitting algorithm has difficulty fitting a high-dimensional model with multiple probability wells in the parameter space. It takes a long time to calculate the probability a model is true for provided data at every point in your parameter space, and this will only increase proportionally to the parameter number. MCMC methods are designed to spend time sampling the most likely parameter sets. Also they do not require a full analytic description of the normalised probability density function (pdf) to begin sampling since only the ratios of the pdf at pairs of locations are calculated, making them ideal for calculating _posterior pdfs_.\n\nIn probabilistic inference, Bayes rule states that the posterior pdf $p\\left(\\theta|D\\right)$ (pdf of parameters $\\theta$ given data $D$) can be determined from the likelihood $p\\left(D|\\theta\\right)$ (pdf of the data given the parameters) and the prior pdf $p\\left(\\theta\\right)$ for the parameters.\n\n<center>$p\\left(\\theta|D\\right)=\\frac{1}{Z}p\\left(D|\\theta\\right)p\\left(\\theta\\right)$</center>\n\nHere, $Z$ is sometimes referred to as the \"marginalised likelihood\" and is incredibly difficult and computationally expensive to calculate. However, since only the ratio $p\\left(\\theta^{\\prime}|D\\right)/p\\left(\\theta|D\\right)$ is important, $Z$ cancels out and the posterior pdf can be sampled."},{"metadata":{},"cell_type":"markdown","source":"## The Metropolis-Hastings Algorithm\n\nThe Metropolis-Hastings (M-H) step is the simplest MCMC algorithm and requires only two inputs: the posterior pdf to be sampled and a proposal algorithm that producess the samples, allowing the algorithm to walk around the parameter space in a fair and random way. The algorithm is as follows:\n\n* Draw a proposal of $\\theta^{\\prime}$ from pdf $q\\left(\\theta^{\\prime}|\\theta_{k}\\right)$ (this is usually a Gaussian distribution centred on the current position).\n* Draw a random number $0<r<1$ from a uniform distribution.\n* If $p\\left(\\theta^{\\prime}\\right)/p\\left(\\theta_{k}\\right)>r$ then $\\theta_{k+1}\\leftarrow\\theta^{\\prime}$; otherwise $\\theta_{k+1}\\leftarrow\\theta_{k}$.\n\nThis produces a random walk which is biased by the acceptance step involving the ratios of the function values. The amount of time the algorithm spends around a location $\\theta$ is proportional to $p\\left(\\theta\\right)$ and samples have to be significantly separated along the chain before they are considered independent from each other. Therefore, fair samples are only produced in the limit of arbitrary run time."},{"metadata":{"trusted":true},"cell_type":"code","source":"mus = np.array([5., 5.])                   # Array of mean values\nsigmas = np.array([[1., 0.9], [0.9, 1.]])  # Covariance matrix\n\ndef pgauss(x, y):\n    \"\"\"\nFunction to calculate the Probability Density Function of a Bivariate Gaussian Distribution.\n    \"\"\"\n    return stats.multivariate_normal.pdf([x, y], mean=mus, cov=sigmas)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Metropolis_Hastings(p, iter=1000):\n    \"\"\"\nBasic Metropolis-Hastings MCMC sampler. Produces a single Markov chain of samples from the parsed Probability Density Function.\n    \"\"\"\n    x, y = 0., 0.                  # Initialise the Markov chain\n    samples = np.zeros((iter, 2))  # Create an empty array in which to store the chain\n    \n    for i in range(iter):  # Iterate over the length of the chain\n        # Calculate proposal based on a Gaussian distribution with a mean of the current position.\n        x_new, y_new = np.array([x, y]) + np.random.normal(2)\n        \n        # Accept or reject stage using M-H rule.\n        if np.random.rand() < (p(x_new, y_new) / p(x, y)):\n            x, y = x_new, y_new\n        samples[i] = np.array(x, y)\n        \n    return samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nNstep = 10000\nprint(\"Total sample number =\", Nstep)\n\ns = Metropolis_Hastings(pgauss, iter=Nstep)  # Run the M-H sampler\n%timeit -n1 s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the samples\nfig = plt.figure(figsize=(6,6))\n\nax = plt.subplot(223)\nax.plot(s[:,0], s[:,1], '.k')\nxlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.set_xlabel('x')\nax.set_ylabel('y')\n\nax = fig.add_subplot(221)\nax.hist(s[:,0], histtype='step', color='k', density=True)\nax.set_xlim(xlims)\nax.set_xticks([])\nax.set_yticks([])\n\nax = fig.add_subplot(224)\nax.hist(s[:,1], histtype='step', color='k', density=True, orientation='horizontal')\nax.set_ylim(ylims)\nax.set_xticks([])\nax.set_yticks([])\n\nfig.tight_layout(h_pad=0., w_pad=0.)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The Rosenbrock Density\n\nThe Rosenbrock density (depicted in the figure below) is an example of a highly anisotropic distribution and is given by the following pdf (Goodman & Weare, 2010).\n\n<center>$\\pi\\left(x_{1},x_{2}\\right)\\propto\\exp\\left(-\\frac{100\\left(x_{2}-x_{1}^{2}\\right)^{2}+\\left(1-x_{1}\\right)^{2}}{20}\\right)$</center>\n\n![Rosenbrock Density](./assets/GoodmanWeare_Rosenbrock.png)\n\nThis kind of distribution is an ideal test case for the efficiency of MCMC algorithms since its degeneracy issues make it difficult to sample. If we imagine beginning a M-H sampler in the infinitesimal probability space surrounding the Rosenbrock density, the sampler will gradually step around the space towards the density, using Gaussian proposal steps, without many issues. The problems arise when the M-H sampler reaches the ridge of the probability density and need to walk along it until it reaches the peak at (0,0). Now, any small deviation from its current position will result in the sampler falling back into infinitesimal probability space. Therefore, the algorithm becomes stuck for a period of time whilst searching for a proposal which will be accepted, wasting valuable computing time. What is required is a sampler that can investigate likely probabilities across the whole pdf without becoming stuck.\n\n<div class=\"alert alert-block alert-info\">\nGenerally, this problem is solved by defining a linear operator that transforms the parameter space into one where Gaussian steps can easily sample the distribution, but this becomes difficult when working with a high-dimensional model.\n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Affine Invariant Ensemble Sampler\n\nThe ability to navigate awkwardly transformed distributions without becoming stuck is known as *affine invariance*. This means that the performance of the method is independent of the aspect ratio in highly anisotropic distributions. A linear affine transformation is the mapping of $\\mathbb{R}^{n}$ to the form $y=Ax+b$. If $X$ has a probability of density of $\\pi\\left(x\\right)$, then $Y=Ax+b$ has the density $\\pi_{A,b}\\left(y\\right)=\\pi_{A,b}\\left(Ax+b\\right)\\propto\\pi\\left(x\\right)$. For example, given the density\n\n<center>$\\pi\\left(x\\right)\\propto\\exp\\Big[\\frac{-\\left(x_{1}-x_{2}\\right)^{2}}{2\\epsilon}-\\frac{\\left(x_{1}+x_{2}\\right)^{2}}{2}\\Big]$</center>\n\nperturbations of order $\\sqrt\\epsilon$ and $1$ can be applied to each term respectively to produce that transformations\n\n<center>$y_{1}=\\frac{x_{1}-x_{2}}{\\sqrt\\epsilon}$, $y_{2}=x_{1}+x_{2}$.</center>\n    \nHence deriving a much simpler distribution to sample in the form of:\n\n<center>$\\pi_{A}\\left(y\\right)\\propto\\exp\\Big[-\\frac{\\left(y_{1}^{2}+y_{2}^{2}\\right)}{2}\\Big]$.</center>\n\n\nThe algorithm used to perform an affine invariant transformation and draw proposals from it is known as the \"stretch move\", depicted in the figure below (Goodman & Weare, 2010).\n\n* To move a walker $X_{k}\\left(t\\right)$, another walker $X_{j}$ is randomly chosen from the rest of the ensemble (i.e. $j\\ne k$).\n* A new position is chosen from a random linear combination of both walkers, or $X_{k}\\left(t\\right)\\rightarrow Y=X_{j}+Z\\left(X_{k}\\left(t\\right)-X_{j}\\right)$.\n* The new position is then accepted or rejected using the Metropolis-Hastings rule, as before.\n\nThe major feature of affine invariant ensemble samplers is that instead of using a single walker, a huge number of walkers can be deployed into the parameter space and all of the information across the ensemble is available to draw new proposals from. This uses the \"parallel stretch move\" which splits the ensemble into two sets and each set is used to update the other's position. Hence if some walkers detect an optimal probability, then more walkers can be brought to the area - and away from any problematic areas - to effectively sample the surrounding parameter space. The Markov quality is preserved however, as the proposal still only depends on the current state of the walkers and not the whole chain.\n\n![Stretch Move](./assets/GoodmanWeare_StretchMove.png)\n\nGoodman and Weare (2010) showed that this algorithm can increase sampling times by $>10$x compared to the Metropolis-Hastings algorithm. This is estimated by the autocorrelation time of the trace (value vs. model number) which is a measure of how often the sampler reaches a new area of parameter space.\n\nIn the cell below, three functions are defined that build the posterior probability distribution using the natural logarithm. This alters the accept/reject step from a ratio of probability values to a subtraction. I.e.:\n\n* If $\\ln fp\\left(\\theta^{\\prime}|D\\right)-\\ln p\\left(\\theta_{k}|D\\right)>\\ln r$ then $\\theta_{k+1}\\leftarrow\\theta^{\\prime}$; otherwise $\\theta_{k+1}\\leftarrow\\theta_{k}$.\n\nThis reduces the probability that the code with encounter underflow or overflow issues."},{"metadata":{"trusted":true},"cell_type":"code","source":"def lnlike(q, data):\n    \"\"\"\nFunction to calculate the log-likelihood probability distribution of a model compared to data, using Gaussian statistics.\n    \"\"\"\n    ll = []            # Empty list to store probabilities in\n    x, y, yerr = data  # Separate data\n\n    for m, c in q:      # Cycle through values\n        ym = m * x + c  # Calculate the model\n        ll.append(-0.5 * np.sum(((y - ym) / yerr) ** 2.))\n    return np.array(ll)\n\ndef lnprior(q):\n    \"\"\"\nFunction to calculate the log-prior probability distribution. This is assumed to be a uniform distribution where the probability\nis zero within the limits and negative-infinity otherwise.\n    \"\"\"\n    u = np.array([0.5, 10.])  # Upper limits\n    l = np.array([-5., 0.])   # Lower limits\n    cond = (l[0]<q[:,0]) & (q[:,0]<u[0]) & (l[1]<q[:,1]) & (q[:,1]<u[1])\n    # Return an array where 0. represents values within the limits, and negative infinity for those outside.\n    lp = np.where(cond, 0., -np.inf)\n    return lp\n\ndef lnprob(q, data):\n    \"\"\"\nFunction to calculate the posterior probability density function.\n    \"\"\"\n    # Calculate the prior\n    lp = lnprior(q)\n    # Calculate the likelihood\n    ll = lnlike(q, data)\n    # Return the posterior\n    lnp = np.where(lp == 0., lp + ll, -np.inf)\n    return lnp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stretch_move(s, c, p0, Npars, data, a=2.):\n    \"\"\"\nFunction to perform the 'stretch move'.\n\n    s : array. The sample to be updated.\n    c : array. The complementary sample used to calculate new positions.\n   p0 : array. The probabilities of s.\nNpars : int. Number of free parameters.\n data : array. Required to calculate probabilities.\n    a : float. The stretch parameter, can be fine-tuned to change the size of the steps taken.\n    \"\"\"\n    Ns = len(s)\n    Nc = len(c)\n    \n    zz = (((a - 1.) * np.random.rand(Ns) + 1.) ** 2.) / a  # Calculates random gradient for the affine linear transformation \n    rint = np.random.randint(Nc, size=(Ns,))  # Calculates a list of integers that will shuffle the complementary sample\n    \n    q = c[rint] - zz[:, np.newaxis] * (c[rint] - s)  # Propose new positions from the linear transformation\n    p = lnprob(q, data)                              # Calculate the posterior probability of the new position\n    \n    p_diff = (Npars - 1) * np.log(zz) + p - p0             # Calucate the difference between the probabilities\n    accept = p_diff > np.log(np.random.rand(len(p_diff)))  # Determine if the new positions are accepted\n    \n    return q, p, accept","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def proposal(q, p, data, Nwalk, Npars):\n    \"\"\"\nFunction to split the current sample into two sets. Then perform the stretch move on each sample to calculate new proposals and\nadd accepted values to the chain.\n\n    q : array. Current positions.\n    p : array. Current probabilities.\n data : array. Required to calculate new probabilities.\nNwalk : int. Number of walkers.\nNpars : int. Number of free parameters.\n    \"\"\"\n    half = int(Nwalk / 2)\n    first, second = slice(half), slice(half, Nwalk)  # Functions to slice the arrays into two sets\n    \n    for S0, S1 in [(first, second), (second, first)]:                       # Loops over each set so they both are updated\n        q_new, p_new, acc = stretch_move(q[S0], q[S1], p[S0], Npars, data)  # Use stretch move to calculate the proposal\n        \n        if np.any(acc):  # Add accepted values into the chains\n            p[S0][acc] = p_new[acc]\n            q[S0][acc] = q_new[acc]\n    \n    return q, p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Ensemble(q0, p0, data, Npars, Nwalk, Nstep):\n    \"\"\"\nFunction to iterate over the Markov chain ensemble.\n\n   q0 : array. Initial positions.\n   p0 : array. Initial probabilities.\n data : array. Data we're trying to find a p.d.f. for.\nNpars : int. Number of free parameters.\nNwalk : int. Number of walkers.\nNstep : Number of Markov steps to take.\n    \"\"\"\n    # Initialise arrays for the Markov chains and the probabilities. Set first elements to provided values.\n    samples = np.ndarray((Nwalk, Nstep, Npars))\n    samples[:,0,:] = np.array(q0)\n    \n    lnprob = np.ndarray((Nwalk, Nstep))\n    lnprob[:,0] = np.array(p0)\n    \n    for i in range(1, Nstep):  # Iterate over the Markov steps\n        q, p = proposal(samples[:,i-1,:], lnprob[:,i-1], data, Nwalk, Npars)  # Calculate and accept/reject the proposal\n        \n        # Add new positions to the chains.\n        samples[:,i,:] = np.array(q)\n        lnprob[:,i] = np.array(p)\n    \n    return samples, lnprob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# True parameters\nmt = -3.4975\nct = 2.479\ntrue = [mt, ct]\nname = ['m', 'c']\n\n# Generate some test data\nN = 50\nx = np.sort(10 * np.random.rand(N))\ny = mt * x + ct\nyerr = 5. * np.random.rand(N)\ny += np.random.normal(loc=0, scale=yerr)\ndata = np.array([x, y, yerr])\n\n# Set up MCMC parameters\nNpars = len(true)\nNwalk = 100\nNstep = 10000\nNburn = 100\n\n# Calculate initial positions and probabilities\nq0 = np.array([[-2.9, 1.9] + 1.e-4*np.random.randn(Npars) for i in range(Nwalk)])  # Gaussian ball centred on initial guess\np0 = lnprob(q0, data)\n\nprint(\"Total sample number =\", Nwalk*Nstep)\n\n# Run the ensemble sampler\nchain = Ensemble(q0, p0, data, Npars, Nwalk, Nstep)\n%timeit -n1 chain\n\nsamples, lnp = chain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot some figures\n# Trace plots\nfig, axes = plt.subplots(Npars, 1, sharex=True)\n\nfor i in range(Npars):\n    for j in range(Nwalk):\n        axes[i].plot(range(Nstep), samples[j,:,i], c='0.5', ls='-')\n    axes[i].axvline(Nburn, c='r')\n    axes[i].axhline(true[i], c='b')\n    axes[i].set_ylabel(name[i])\naxes[-1].set_xlabel('Model number')\nfig.tight_layout()\nplt.show()\n\n# Corner plot\ntmp = samples[:,Nburn:,:]\ns = tmp.reshape(tmp.shape[0]*tmp.shape[1], tmp.shape[2])\n\nfig, axes = plt.subplots(Npars, Npars)\nfig.delaxes(axes[0,1])\n\n# Histograms\nfor i in range(Npars):\n    ax = axes[i,i]\n    ax.hist(s[:,i], histtype='step', color='k', density=True)\n    ax.axvline(true[i], c='b')\n    if i == (Npars - 1):\n        ax.set_yticks([])\n        ax.set_xlabel(name[i])\n    else:\n        ax.set_xticks([])\n        ax.set_yticks([])\n\n# Densities\nfor i in range(Npars):\n    for j in range(Npars):\n        if i <= j:\n            pass\n        else:\n            ax = axes[i,j]\n            ax.plot(s[:,j], s[:,i], marker='.', c='0.5', ls=' ')\n            ax.axvline(true[j], c='b')\n            ax.axhline(true[i], c='b')\n            if i < (Npars - 1):\n                ax.set_xticks([])\n            if (i == 2) & (j < Npars):\n                ax.set_yticks([])\n            if i == (Npars - 1):\n                ax.set_xlabel(name[j])\n            if j == 0:\n                ax.set_ylabel(name[i])\nfig.tight_layout()\nplt.show()\n\n# Plot data and model\nm, c = np.mean(s[:,0]), np.mean(s[:,1])\n\nprint('m = {0:.3f} +/- {1:.3f} (true: {2:.3f})'.format(m, np.std(s[:,0]), mt))\nprint('c = {0:.3f} +/- {1:.3f} (true: {2:.3f})'.format(c, np.std(s[:,1]), ct))\n\nplt.errorbar(x, y, yerr=yerr, fmt='.k', capsize=0)\nplt.plot(x, mt*x+ct, '-b', label='True values')\nplt.plot(x, m*x+c, '-r', label='Model')\nplt.legend(loc='upper right')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\nMCMC is an important class of algorithm in science because it allows us to sample difficult pdfs of complex models without having a full analytical description, giving us an alternative method when other analytical approaches fall short. They are simple algorithms to construct, while being flexible and scalable to a variety of different scenarios, and can save valuable computational time by sampling only the most likely probabilities. The Affine Invariant Ensemble Sampler in particular is adept at navigating complex pdfs, compared to the M-H step, due to its ability to use the information gathered across the whole ensemble of walkers to draw proposals and step through parameter space. This knowledge of the other walkers' positions allows the ensemble to draw more walkers into regions of optimal probability and spend less time stuck in undesirable regions.\n\nMCMC is a very powerful and popular tool within Astronomy and has successfully been implemented to [infer the orbit of a comet](https://arxiv.org/abs/1103.6038) and [fit the stellar structure of the Milky Way](https://arxiv.org/abs/1111.1724)."},{"metadata":{},"cell_type":"markdown","source":"## References\n\n* Foreman-Mackey, Hogg, Lang & Goodman (2013) Publications of the Astronomical Society of the Pacific, 125(925), 306\n* Goodman & Weare (2010) Comm. App. Math & Comp. Sci, Vol. 5, No. 1\n* Hogg & Foreman-Mackey (2017) ApJ Supplement series, 236(1), 11\n\n* [Astrobites - Code you can use: the MCMC Hammer](https://astrobites.org/2012/02/20/code-you-can-use-the-mcmc-hammer/)\n* [Augustinus Kristiadi - Tech Blog: Metropolis-Hastings](https://wiseodd.github.io/techblog/2015/10/17/metropolis-hastings/)\n* [emcee: The MCMC Hammer Documentation](http://dfm.io/emcee/current/)"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}